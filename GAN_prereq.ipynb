{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP/sfCHcNW69z+u4/zLc90h"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"kwkipCeEeLSL","executionInfo":{"status":"ok","timestamp":1741684701948,"user_tz":-330,"elapsed":7005,"user":{"displayName":"GOTETI SAI ABHINAV","userId":"18197951641538660913"}}},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset,DataLoader\n"]},{"cell_type":"code","source":["# Step 1: Create a custom dataset\n","class CustomDataset(Dataset):\n","    def __init__(self, data, targets):\n","        \"\"\"\n","        Args:\n","            data (list): List of input data.\n","            targets (list): List of corresponding labels/targets.\n","        \"\"\"\n","        self.data = data\n","        self.targets = targets\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"\n","        Returns a single sample and its corresponding target.\n","        \"\"\"\n","        sample = self.data[idx]\n","        target = self.targets[idx]\n","        return sample, target\n"],"metadata":{"id":"U6SU6hnMeZtc","executionInfo":{"status":"ok","timestamp":1741684701962,"user_tz":-330,"elapsed":2,"user":{"displayName":"GOTETI SAI ABHINAV","userId":"18197951641538660913"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Step 2: Create dummy data\n","data = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0], [7.0, 8.0]])\n","targets = torch.tensor([0, 1, 0, 1])"],"metadata":{"id":"YgWalySQfex7","executionInfo":{"status":"ok","timestamp":1741684701994,"user_tz":-330,"elapsed":32,"user":{"displayName":"GOTETI SAI ABHINAV","userId":"18197951641538660913"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Step 3: Create a dataset instance\n","dataset = CustomDataset(data, targets)"],"metadata":{"id":"R3TfXYarffyh","executionInfo":{"status":"ok","timestamp":1741684702007,"user_tz":-330,"elapsed":10,"user":{"displayName":"GOTETI SAI ABHINAV","userId":"18197951641538660913"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Step 4: Create a DataLoader\n","dataloader = DataLoader(\n","    dataset,          # Dataset to load\n","    batch_size=2,     # Number of samples per batch\n","    shuffle=True,     # Shuffle the data\n","    num_workers=0     # Number of subprocesses for data loading (0 means no parallel loading)\n",")"],"metadata":{"id":"k_wLI8ePfmuh","executionInfo":{"status":"ok","timestamp":1741684702014,"user_tz":-330,"elapsed":5,"user":{"displayName":"GOTETI SAI ABHINAV","userId":"18197951641538660913"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Step 5: Iterate over the DataLoader\n","for batch_idx, (batch_data, batch_targets) in enumerate(dataloader):\n","    print(f\"Batch {batch_idx + 1}:\")\n","    print(f\"Data: {batch_data}\")\n","    print(f\"Targets: {batch_targets}\")\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iZLhm7zwfqHQ","executionInfo":{"status":"ok","timestamp":1741684702177,"user_tz":-330,"elapsed":161,"user":{"displayName":"GOTETI SAI ABHINAV","userId":"18197951641538660913"}},"outputId":"7c98f3e9-34d9-435b-d355-64e6faa770fa"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch 1:\n","Data: tensor([[3., 4.],\n","        [5., 6.]])\n","Targets: tensor([1, 0])\n","\n","Batch 2:\n","Data: tensor([[7., 8.],\n","        [1., 2.]])\n","Targets: tensor([1, 0])\n","\n"]}]},{"cell_type":"code","source":["import torch.nn as nn\n","# Define input (batch size = 1, channels = 1, height = 5, width = 5)\n","input = torch.tensor([[\n","    [1, 2, 3, 4, 5],\n","    [6, 7, 8, 9, 10],\n","    [11, 12, 13, 14, 15],\n","    [16, 17, 18, 19, 20],\n","    [21, 22, 23, 24, 25]\n","]], dtype=torch.float32).unsqueeze(0)  # Add batch and channel dimensions\n","print(input.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZZ84VkP7f5V4","executionInfo":{"status":"ok","timestamp":1741684779242,"user_tz":-330,"elapsed":61,"user":{"displayName":"GOTETI SAI ABHINAV","userId":"18197951641538660913"}},"outputId":"2b108b33-1522-4c34-fb5d-4672aaa9a0d1"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 1, 5, 5])\n"]}]},{"cell_type":"code","source":["# Define a convolution layer\n","conv_layer = nn.Conv2d(  # preferred in encoder\n","    in_channels=1,       # Input channels\n","    out_channels=1,      # Output channels\n","    kernel_size=3,       # Kernel size (3x3)\n","    stride=1,            # Stride\n","    padding=0            # No padding\n",")"],"metadata":{"id":"5xwRdMzegKdF","executionInfo":{"status":"ok","timestamp":1741684860318,"user_tz":-330,"elapsed":40,"user":{"displayName":"GOTETI SAI ABHINAV","userId":"18197951641538660913"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Define a deconvolution (transposed convolution) layer\n","deconv_layer = nn.ConvTranspose2d( # preferred in decoder\n","    in_channels=1,       # Input channels\n","    out_channels=1,      # Output channels\n","    kernel_size=3,       # Kernel size (3x3)\n","    stride=1,            # Stride\n","    padding=0            # No padding\n",")"],"metadata":{"id":"s_9spttBgT7n","executionInfo":{"status":"ok","timestamp":1741684858302,"user_tz":-330,"elapsed":2,"user":{"displayName":"GOTETI SAI ABHINAV","userId":"18197951641538660913"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Perform convolution\n","output_conv = conv_layer(input)\n","print(\"Convolution Output:\")\n","print(output_conv)\n","\n","# Perform deconvolution\n","output_deconv = deconv_layer(output_conv)\n","print(\"\\nDeconvolution Output:\")\n","print(output_deconv)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vyedO0wVgdxI","executionInfo":{"status":"ok","timestamp":1741684874319,"user_tz":-330,"elapsed":60,"user":{"displayName":"GOTETI SAI ABHINAV","userId":"18197951641538660913"}},"outputId":"f3ab04cc-d5d7-4a8b-d648-586188f10f51"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Convolution Output:\n","tensor([[[[-6.5565, -6.6727, -6.7889],\n","          [-7.1374, -7.2536, -7.3698],\n","          [-7.7183, -7.8345, -7.9507]]]], grad_fn=<ConvolutionBackward0>)\n","\n","Deconvolution Output:\n","tensor([[[[-0.0909, -1.5911, -1.7132, -1.5599, -0.0114],\n","          [ 1.2751,  0.2821, -0.3465, -1.6067, -0.5722],\n","          [ 0.3417, -2.8264, -3.7623, -4.0925, -0.8312],\n","          [ 0.5782, -0.9540, -1.8161, -2.3609, -0.7837],\n","          [-1.1403, -3.6056, -3.8922, -2.6710, -0.1539]]]],\n","       grad_fn=<ConvolutionBackward0>)\n"]}]},{"cell_type":"code","source":["# Define a convolutional block using nn.Sequential\n","conv_block = nn.Sequential(\n","    # Convolutional layer\n","    nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),\n","    # Batch normalization layer\n","    nn.BatchNorm2d(64),\n","    # ReLU activation function\n","    nn.ReLU(inplace=True)\n",")\n","# Print the convolutional block\n","print(conv_block)\n","# Example input tensor (batch_size, channels, height, width)\n","input_tensor = torch.randn(1, 3, 32, 32)\n","# Forward pass through the convolutional block\n","output_tensor = conv_block(input_tensor)\n","# Print the shape of the output tensor\n","print(output_tensor.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LtwDIgLughql","executionInfo":{"status":"ok","timestamp":1741684947355,"user_tz":-330,"elapsed":29,"user":{"displayName":"GOTETI SAI ABHINAV","userId":"18197951641538660913"}},"outputId":"d821df01-28cc-4cd0-ed83-4896b4694399"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequential(\n","  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (2): ReLU(inplace=True)\n",")\n","torch.Size([1, 64, 32, 32])\n"]}]},{"cell_type":"code","source":["# Define a simple linear regression model\n","class LinearRegression(nn.Module):\n","    def __init__(self):\n","        super(LinearRegression, self).__init__()\n","        self.linear = nn.Linear(1, 1)  # 1 input feature, 1 output\n","\n","    def forward(self, x):\n","        return self.linear(x)\n","# Create model, loss function, and optimizer\n","model = LinearRegression()\n","criterion = nn.MSELoss()  # Mean Squared Error Loss\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # weights, bias, learning rate\n","# Dummy data (y = 2x + 1)\n","x = torch.tensor([[1.0], [2.0], [3.0], [4.0]])\n","y = torch.tensor([[3.0], [5.0], [7.0], [9.0]])\n","# Training loop\n","for epoch in range(100):\n","    # Forward pass\n","    predictions = model(x) # forward method is automatically called when you pass data into model\n","    loss = criterion(predictions, y) # MSE\n","    # Backward pass and optimization\n","    optimizer.zero_grad() # clear gradients from previous iteration\n","    loss.backward() # compute weights by backprop\n","    optimizer.step() # update weights and bias\n","    if (epoch + 1) % 10 == 0:\n","        print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')\n","\n","# Test the model\n","test_x = torch.tensor([[5.0]])\n","predicted_y = model(test_x)\n","print(f'Prediction for input {test_x.item()}: {predicted_y.item():.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H-FxcDvpgzgZ","executionInfo":{"status":"ok","timestamp":1741685327003,"user_tz":-330,"elapsed":49,"user":{"displayName":"GOTETI SAI ABHINAV","userId":"18197951641538660913"}},"outputId":"2fb0b81a-a1cf-423b-92e8-d4b945eb3b03"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/100], Loss: 1.6223\n","Epoch [20/100], Loss: 0.1157\n","Epoch [30/100], Loss: 0.0724\n","Epoch [40/100], Loss: 0.0673\n","Epoch [50/100], Loss: 0.0633\n","Epoch [60/100], Loss: 0.0596\n","Epoch [70/100], Loss: 0.0562\n","Epoch [80/100], Loss: 0.0529\n","Epoch [90/100], Loss: 0.0498\n","Epoch [100/100], Loss: 0.0469\n","Prediction for input 5.0: 10.6297\n"]}]},{"cell_type":"code","source":["# Define a simple binary classification model\n","class BinaryClassifier(nn.Module):\n","    def __init__(self):\n","        super(BinaryClassifier, self).__init__()\n","        self.linear = nn.Linear(1, 1)  # 1 input feature, 1 output\n","        self.sigmoid = nn.Sigmoid()    # Sigmoid activation for binary classification\n","\n","    def forward(self, x):\n","        return self.sigmoid(self.linear(x))\n","\n","# Create model, loss function, and optimizer\n","model = BinaryClassifier()\n","criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n","\n","# Dummy data (y = 0 for x < 2.5, y = 1 for x >= 2.5)\n","x = torch.tensor([[1.0], [2.0], [3.0], [4.0]])\n","y = torch.tensor([[0.0], [0.0], [1.0], [1.0]]) # 0-> fake, 1-> real\n","\n","# Training loop\n","for epoch in range(100):\n","    # Forward pass\n","    predictions = model(x)\n","    loss = criterion(predictions, y)\n","\n","    # Backward pass and optimization\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (epoch + 1) % 10 == 0:\n","        print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')\n","\n","# Test the model\n","test_x = torch.tensor([[2.0], [3.0]])\n","predicted_y = model(test_x)\n","print(f'Predictions for input {test_x.squeeze().tolist()}: {predicted_y.squeeze().tolist()}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OCjHWB24g9Ia","executionInfo":{"status":"ok","timestamp":1741685390068,"user_tz":-330,"elapsed":73,"user":{"displayName":"GOTETI SAI ABHINAV","userId":"18197951641538660913"}},"outputId":"7cbea590-ab36-4798-82a2-e739bf46fb96"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/100], Loss: 0.5192\n","Epoch [20/100], Loss: 0.4917\n","Epoch [30/100], Loss: 0.4757\n","Epoch [40/100], Loss: 0.4610\n","Epoch [50/100], Loss: 0.4473\n","Epoch [60/100], Loss: 0.4344\n","Epoch [70/100], Loss: 0.4223\n","Epoch [80/100], Loss: 0.4109\n","Epoch [90/100], Loss: 0.4002\n","Epoch [100/100], Loss: 0.3901\n","Predictions for input [2.0, 3.0]: [0.5055983662605286, 0.7108482122421265]\n"]}]},{"cell_type":"code","source":["# plotting losss\n"],"metadata":{"id":"yh02QgA5iX4N"},"execution_count":null,"outputs":[]}]}